---
title:          "Stronger Models are NOT Stronger Teachers for Instruction Tuning"
date:           2025-01-11 00:01:00 +0800
selected:       false
# pub:            "Annual Conference of the Nations of the Americas Chapter of the ACL (NAACL"
pub: "NAACL 2025"
pub_date:       "2025"
abstract: >-
  This paper challenges the common assumption that larger models are inherently better teachers for instruction tuning, revealing a "Larger Models' Paradox" where stronger models don't necessarily yield better results when fine-tuning smaller models. To address this, the authors propose a novel metric—Compatibility-Adjusted Reward (CAR)—which more accurately predicts the effectiveness of response generators by considering compatibility between teacher and base models, outperforming existing metrics across various experiments.  
cover:          /assets/images/covers/img_lmp.png
authors:
- Zhangchen Xu
- Fengqing Jiang
-  Luyao Niu
-   Bill Yuchen Lin
-    Radha Poovendran
links:
  Preprint: https://arxiv.org/abs/2411.07133
---